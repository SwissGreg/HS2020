\documentclass[8pt]{extreport}
\usepackage{parskip}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{enumitem}
\usepackage{geometry}
\usepackage{float}
\geometry{a4paper, margin=1in}
\title{Visual Computing\\ Summary}

\begin{document}
	\maketitle
	\newpage
\chapter{The Digital Image}

\section{What is an image:}

\paragraph{\underline{Signal:}} A function depending on some variable with physical meaning

\paragraph{\underline{Image:}} A continuous function. The value can take on physical values. e.g Brightness, temperature, pressure, depth, etc. We distinguish images with:
\begin{itemize}
\item \textbf{2 variables:} xy- coordinates
\item \textbf{3 variables:} xy + time (video)
\end{itemize}
Hence an image is a picture or pattern of a value varying in space and/or time.
\begin{center}
$f: \mathbb{R}^n \rightarrow S$
\end{center}

\section{The digital camera}
\begin{figure}[H]
\centering
\includegraphics[width = 70mm]{VC1.png}
\end{figure}


\paragraph{\underline{The sensor array:}} An array of photosites. Each photosite is a bucket of electrical charge and contain a charge proportional to the incident light intensity during exposure.

\paragraph{\underline{Analog to Digital Conversion:}} The ADC measures the charge and digitizes the result. The conversion happens line by line. The charges in each photosite move down through the sensor array.

\begin{figure}[H]
\centering
\includegraphics[width = 70mm]{VC2.png}
\end{figure}

Various errors:
\begin{itemize}
\item \textbf{Blooming:} The buckets have finite capacity, saturation causes blooming. It happens when a large amount of light gets focused to a single point on your cameras image sensor. This can create so much charge that it actually bleeds from pixel to pixel until it eventually spreads out.

\begin{figure}[H]
\centering
\includegraphics[width = 40mm]{VC3.png}
\end{figure}
\item \textbf{Bleeding or Smearing:} During transit buckets still accumulate some charges. The amount is influenced by the time "in transit" versus the integration time
\begin{figure}[H]
\centering
\includegraphics[width = 40mm]{VC5.png}
\end{figure}
\item \textbf{Dark Current:} A relatively small electric current that flows through photosensitive devices even when no photons are entering the device.
\begin{figure}[H]
\centering
\includegraphics[width = 40mm]{VC4.png}
\end{figure}
\end{itemize}

\paragraph{\underline{CMOS:}} Contains the same sensor elements as CCD but each photo sensor has its own amplifier. the benefits:
\begin{itemize}
\item Recent technology
\item Standard IC technology
\item Cheap
\item Low Power
\item Less sensitive
\item Per pixel amplification
\item Random pixel access
\item Smart pixels
\item On chip integration with other components
\end{itemize}

\section{Sampling 1D:}

Sampling in 1D takes a function, and returns a vector whose elements are values of that function at the sample points.

\begin{figure}[H]
\centering
\begin{subfigure}[b]{0.3\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC6.png}
\end{subfigure}
\begin{subfigure}[b]{0.3\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC7.png}
\end{subfigure}
\end{figure}
\subsection{Reconstruction:} Making samples back into a continuous function. This amounts to guessing what the function did in between the individual samples

\subsection{Undersampling:} Occurs if not enough sampling points are available. It results in a loss of information and can be indistinguishable from other samples e.g undersampling a sin wave:
\begin{figure}[H]
\centering
\begin{subfigure}[b]{0.3\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC8.png}
\end{subfigure}
\begin{subfigure}[b]{0.3\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC9.png}
\end{subfigure}
\end{figure}


\section{Sampling 2D:}

Sampling in 2D takes a function and returns an array. The array can have infinite dimensions and have negative as well as positive indices.

\subsection{Reconstruction continuous signals:}
\begin{figure}[H]
\centering
\begin{subfigure}[b]{0.3\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC10.png}
\end{subfigure}

\end{figure}

\subsection{ Nyquist Frequency:} Half the sampling frequency of a discrete signal processing system. The signals max frequency (bandwidth) must be smaller than this.

\subsection{ Quantization:} Real valued function gets digital values (integer values). Quantization is lossy i.e the orignial signal cannot be reconstructed anymore. Simple quantization uses equally spaced levels with k intervals:
\begin{center}
$ k= 2^b$
\end{center}
\begin{figure}[H]
\centering
\begin{subfigure}[b]{0.3\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC11.png}
\end{subfigure}
\begin{subfigure}[b]{0.3\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC12.png}
\end{subfigure}
\begin{subfigure}[b]{0.3\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC13.png}
\end{subfigure}
\end{figure}

\subsection{Image Properties:}

\paragraph{\underline{Geometric Resolution:}} How many pixels per area

\paragraph{\underline{Radiometric Resolution:}} How many bits ber pixel

\section{Image Noise}

The different types of common Noise models:

\begin{itemize}
\item \textbf{\underline{Gaussian noise:}}
\begin{center}
$I(x,y) = f(x,y) + c$
\end{center}
 where $c \sim N(0,\sigma^2)$ so that 
\begin{center}
$p(c) = (2\pi\sigma^2)^{-1}e^{\frac{-c^2}{2\sigma^2}}$
\end{center}

\item  \textbf{\underline{Poisson noise:}}
\begin{center}
$p(k) = \frac{\lambda^k e^{-\lambda}}{k!}$
\end{center}
\item \textbf{\underline{Rician noise:}}
\begin{center}
$p(I) = \frac{I}{\sigma^2}e^{\frac{-(I^2 + f^2)}{2\sigma^2}}I_0(\frac{If}{\sigma^2}$
\end{center}
\item \textbf{\underline{Multiplicative noise:}}
\begin{center}
$I = f + fc$
\end{center}
\end{itemize}

\paragraph{\underline{Signal to noise ration (SNR)}} An index of image quality:
\begin{center}
$s = \frac{F}{\sigma}$ where $F= \frac{1}{XY}\displaystyle\sum_{x=1}^{X}\displaystyle\sum_{y=1}{Y}f(x,y)$
\end{center}

\paragraph{\underline{Peak Signal to Noise Ration (PSNR)}}
\begin{center}
$s_{peak} = \frac{F_{max}}{\sigma}$
\end{center}

\section{Color Cameras:}

\paragraph{\underline{Prism Color Camera:}} Seperates the light into 3 beams using a dichroic prism
\begin{figure}[H]
\centering
\begin{subfigure}[b]{0.3\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC14.png}
\end{subfigure}
\end{figure}
\paragraph{\underline{Filter mosaic:}} Filter is coated directly on sensor

\paragraph{\underline{Filter wheel:}} Rotate multiple filters in front of lens. This is only suitable for static scenes.
\begin{figure}[H]
\centering
\begin{subfigure}[b]{0.3\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC15.png}
\end{subfigure}
\end{figure}

\chapter{Image Segmentation:}

Image segmentation is the concept of partitioning an image into regions of interest.

\paragraph{\underline{Complete Segmentation:}} A finite set of regions $R_1, ..., R_N$, such that
\begin{center}
$I = \bigcup\limits_{i=1}^{N}R_i$ and  $R_i \cap R_j = \phi \quad \forall i\neq j$
\end{center}
Where I is an image.

\section{Thresholding}

Thresholding is a simple segmentation process which produces a binary image B. It labels each pixel "in" or "out" of the region of interest by comparison of the greylevel with a threshold T:
\[ 
B(x,y) =
\begin{cases}
1 \quad \text{ if } I(x,y) \geq T\\
0 \quad \text{ if } I(x,y) < T\\
\end{cases}
\]

\begin{figure}[H]
\centering
\begin{subfigure}[b]{0.3\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC16.png}
\end{subfigure}
\begin{subfigure}[b]{0.3\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC17.png}
\end{subfigure}
\begin{subfigure}[b]{0.3\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC18.png}
\end{subfigure}
\begin{subfigure}[b]{0.3\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC19.png}
\end{subfigure}
\end{figure}

\section{ROC Analysis}

ROC = Reciever Operating Characteristic\\

An ROC curve characterizes the performance of a binary classifier. A binary classifier distinguishes between two different types of things e.g:
\begin{itemize}
\item Healthy/afflicted patients 
\item Pregnancy tests
\item Object detection
\item Foreground/background image pixels
\end{itemize}

\subsection{Classification Error}
Binary classifiers make errors. There are two inputs to a binary classifier i.e positives and negatives but there are four possible outcomes in any test:
\begin{figure}[H]
\centering
\begin{subfigure}[b]{0.5\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC20.png}
\end{subfigure}
\end{figure}

\subsection{ROC Curve}
Characterizes the error trade-off in binary classification tasks. It plots the TP (True-positive) against the FP (False-positive) fraction

\begin{center}
TP fraction (sensitivity): $\frac{\text{ True positive count } }{P}$\\
FP fraction (1-specificity):$ \frac{\text{ False positive count } }{N}$
\end{center}

An ROC curve always passes through (0,0) and (1,1)\\
We choose an operating point by assigning a relative costs and values to each outcome:
\begin{itemize}
\item $V_{TN}$ Value of true negative
\item $V_{TP}$ Value of a true positive
\item $C_{FN}$ Cost of a false negative
\item $C_{FP}$ Cost of a false positive
\end{itemize}

We choose the point on the ROC curve with gradient:
\begin{center}
$\beta = \frac{N}{P}\frac{V_{TN} + C_{FP}}{V_{TP} + C_{FN}}$
\end{center}
For simplicity we often set $V_{TN} = V_{TP} = 0$
\begin{figure}[H]
\centering
\begin{subfigure}[b]{0.5\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC21.png}
\end{subfigure}
\end{figure}


In reality we use 2-3 seperate sets of test data:
\begin{enumerate}
\item \textbf{Training set:} For tuning the algorithm
\item \textbf{Validation set:} For tuning the performance score
\item \textbf{Test set:} To get a final performance score on the tuned algorithm
\end{enumerate}

\section{Pixel Connectivity:}

\paragraph{\underline{Pixel Neighbourhood:}}
\begin{figure}[H]
\centering
\begin{subfigure}[b]{0.5\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC22.png}
\end{subfigure}
\end{figure}

\paragraph{\underline{Pixel Paths:}}
\begin{itemize}
\item A 4-connected path between pixels $p_1$ and $p_n$ is a set of pixels $\{p_1,p_2,...,p_n\}$ such that $p_i$ is a 4-neighbour of $p_{i+1}$ i=1,...,n-1
\item A  8-connected path, $p_i$ is an 8-neighbour of $p_{i+1}$
\end{itemize}

\paragraph{\underline{Connected Regions:}}
\begin{itemize}
\item A region is 4-connected if it contains a 4-connected path between any two of its pixels
\item A region is 8-connected if it contains an 8-connected path between any two of its pixels
\end{itemize}

\section{Image Labelling}

\paragraph{\underline{Connected components Labelling:}} Labels each connected component of a binary image with a seperate number
\begin{figure}[H]
\centering
\begin{subfigure}[b]{0.5\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC23.png}
\end{subfigure}
\end{figure}

\paragraph{\underline{Foreground Labelling:}} Only extract the connected components of the foreground
\begin{figure}[H]
\centering
\begin{subfigure}[b]{0.5\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC24.png}
\end{subfigure}
\end{figure}

\paragraph{\underline{Region Growing:}} Start from a seed point or region and add neighbouring pixels that satisgy the criteria defining a region, we repeat until we can include no more pixels. 
There are 3 meaningful variations when considering region Growing:
\begin{itemize}
\item Seed Selection i.e from where do we start the region growing
\item Inclusion criteria 
\item Boundary constraints and snakes i.e how can the boundary evolve.
\end{itemize}

\paragraph{Seed selection:} We can select a seed point or region by hand or automatically e.g from a conservative thresholding. Multiple seeds can be chosen aswell. 

\paragraph{Inclusion Criteria:} Until now we have looked at Greylevel thresholding. Another possibility would be to use a Greylevel distribution model. We use a mean $\mu$ and a standard deviation $\sigma$ in the seed region. We include the pixel if:
\begin{center}
$(I(x,y) - \mu)^2 < (n\sigma)^2$ 
\end{center}
We can update the mean and standard deviation after every iteration.

\paragraph{\underline{snakes}} A snake is an active contour. It is a polygon i.e an ordered set of points joined up by lines. Each point on the contour moves away from the seed while its image neighborhood satisfies an inclusion criterion. contours usually have smoothness constraints. To avoid snakes the algorithm iteratively minimizes an energy function:
\begin{center}
$E = E_{tension} + E_{stiffness} + E_{image}$
\end{center}
Stiffness and tension are used to keep the region from growing too much and grow in a regular way.



\paragraph{\underline{Markov Random Fields:}}
\begin{figure}[H]
\centering
\begin{subfigure}[b]{0.49\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC25.png}
\end{subfigure}
\begin{subfigure}[b]{0.49\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC26.png}
\end{subfigure}
\end{figure}
 The Energy Function consists of two terms. The first term is an unary  term i.e only considering the current pixel e.g wether or not the pixel is foreground (F) or background (BG) and the second term is a pairwise term which has 4 possible states: F F, F BG, BG F, BG BG. Usually we favor pixels agreeing with eachother, hence these pixels will have a lower energy. Our goal is to minimize this energy function. One way to solve this is using graph cuts i.e Min-Cut Max Flow
\begin{figure}[H]
\centering
\begin{subfigure}[b]{0.49\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC27.png}
\end{subfigure}
\begin{subfigure}[b]{0.49\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC28.png}
\end{subfigure}
\end{figure}
We want to find a cut such that all the foreground pixels are connected to one side and the background pixels connected to the other side while minimizing the separation of the two. The cost in the cut in the picture on the right is the pairwise cost of cutting the three boundary edges (3K) and the data cost for labelling each pixel to the source or the sink.\\
Terminoligy:
\begin{itemize}
\item \underline{\textbf{Cut:}} Separates source from sink
\item \underline{\textbf{Energy:}} Collection of edges
\item \underline{\textbf{Min Cut:}} Global minimal energy
\end{itemize}
The Min-Cut can be found in polynomial time.

\paragraph{\underline{Iterated Graph Cut:}} Given the picture the user picks a rough boundary which contains all of the pixels which belong to the foreground. We look at the 2 distribution of colours inside and outside of the chosen boundary. We then apply \textbf{K-means clustering} which is a method in which we define K clusters and assign each pixel to one of the clusters. After assigning the clusters we check wether or not the cluster fits better to the distribution of the foreground or background and assign it to the corresponding match. The background model can then retrain itself with the newly assigned background pixels to achieve an even tighter foreground model. Using this method it is guaranteed that we saturate at a certain energy level and dont oscillate between values. The saturated energy value is not necissarily a local or global minimium.
\begin{figure}[H]
\centering
\begin{subfigure}[b]{0.32\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC29.png}
\end{subfigure}
\begin{subfigure}[b]{0.32\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC30.png}
\end{subfigure}
\begin{subfigure}[b]{0.32  \linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC31.png}
\end{subfigure}
\end{figure}

\section{Morphological Operations}

Operations which are purely spatial. Hence we wont use data driven operations. They are local pixel transformations for processing region shapes. Most often used on binary images. Logical transformations based on comparison of pixel neighbourhoods with a pattern.
Some examples:
\begin{itemize}
\item \underline{\textbf{8-neighbour erode (Minkowsky Subtraction)}} if the current pixel has an 8-neighbour which belongs to the background add it to the background.
\begin{figure}[H]
\centering
\begin{subfigure}[b]{0.32\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC32.png}
\end{subfigure}
\end{figure}
\item  \underline{\textbf{8-neighbour dilate (Minkowsky Addition)}} Paint any background pixel that has one eight-connected neighbour that is foreground 
\end{itemize}
Morphological Operation are used to smooth region boundaries for shape analysis and can be used to remove noise and artefacts from an imperfect segmentation.


\paragraph{\underline{Structuring Elements}}The structuring element is a binary array indicating pixels of interest in a region. A structuring element has an origin. Morphological operations take two arguments
\begin{itemize}
\item A binary image
\item A structuring element
\end{itemize}
We compare the structuring element to the neighbourhood of each pixel, this determines the output of the morphological operation.\\    
We define 3 operations (S is a structuring element) :
\begin{itemize}
\item \underline{\textbf{Fitting:}} S fits I at $\underline{x}$ if
\begin{center}
$\{y:y = \underline{x} + \underline{s}, \underline{s} \in S\} \subset I$
\end{center}
\item \underline{\textbf{Hitting:}}S hits I at $\underline{x}$ if
\begin{center}
$\{\underline{y}:\underline{y} = \underline{x} - \underline{s}, \underline{s} \in S\} \cap I  \neq \emptyset$
\end{center}
\item \underline{\textbf{Missing:}}S misses I at $\underline{x}$ if
\begin{center}
$\{\underline{y}:\underline{y} = \underline{x} - \underline{s}, \underline{s} \in S\} \cap I  = \emptyset$
\end{center}
\end{itemize}

\begin{figure}[H]
\centering
\begin{subfigure}[b]{0.32\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC33.png}
\end{subfigure}
\end{figure}
The above picture there are 3 regions of interest: upper left, upper right, down center:
\begin{itemize}
\item For the upper left region the structuring element origin placed in the center all the ones coincide with the ones in the region
\item The upper right region demonstrates hits: We place the structuring element origin at all the squares with one e.g the middle square which is 0 is covered by a one in the structuring element and is hence a hit.
\item The down center image demonstrates a miss. We place the structuring element origin at all the squares with a one but the middle 0 does not get covered with a one and hence its a miss.
\end{itemize}

\underline{\textbf{Erosion:}} The image $E = I  \ominus S$ is the erosion of image I by structuring element S:
\[
E(\underline{x}) =
\begin{cases}
1 \quad \text{if S fits I at } \underline{x}\\
0 \quad \text{ otherwise}
\end{cases}
\]
 \begin{center}
$E =\{x:x + s \in I \text{ for every } s \in S\}$
\end{center}
\begin{figure}[H]
\centering
\begin{subfigure}[b]{0.32\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC34.png}
\end{subfigure}
\end{figure}

\underline{\textbf{Dilation:}} The image $D = I  \oplus S$ is the dilation of image I by structuring element S:
\[
D(\underline{x}) =
\begin{cases}
1 \quad \text{if S hits I at } \underline{x}\\
0 \quad \text{ otherwise}
\end{cases}
\]
 \begin{center}
$D =\{\underline{x}:\underline{x} - \underline{ s},\underline{y} \in I \text{ and } \underline{s}  \in S\}$
\end{center}
\begin{figure}[H]
\centering
\begin{subfigure}[b]{0.32\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC35.png}
\end{subfigure}
\end{figure}

\underline{\textbf{Opening}} The opening of I by S is 
\begin{center}
$I \circ S = (I \ominus S) \oplus S$
\end{center}

\underline{\textbf{Closing}} The closing of I by S is
\begin{center}
$I \bullet S =(I \oplus S) \ominus$
\end{center}

\begin{figure}[H]
\centering
\begin{subfigure}[b]{0.32\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC36.png}
\end{subfigure}
\end{figure}

Morphological filtering uses both opening and closing to remove holes in the foreground and islands in the background. The size and shape of the structuring element determine which features survive. In the absence of knowledge about the shape of features to remove, use a circular structuring element.

\underline{\textbf{Granulometry:}} Provides a size distribution of distinct regions or "granules" in the image. We open the image with increasing structuring element size and count the number of regions after each operation. This creates a "morphological sieve". (e.g counting red blood cells)

\underline{\textbf{Hit-and-miss transform}} Searches for an exact match of the structuring element. $H = I \otimes S$ is the hit-and-miss transform of image I by structuring element S. It is a simple form of template matching
\begin{figure}[H]
\centering
\begin{subfigure}[b]{0.32\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC37.png}
\end{subfigure}
\end{figure}
The $*$ indicates a dont care hence can either be zero or one

\underline{\textbf{Thinning and Thickening}} Defined in terms of the hit-and-miss transform:
\begin{itemize}
\item The thinning of I by S is:
\begin{center}
$ I \oslash S = I\backslash (I \otimes S)$
\end{center}
\item The thickening of I by S is:
\begin{center}
$ I \odot S = I \cup (I \otimes S)$
\end{center}
\end{itemize}
We have the following equality:
\begin{center}
$I \odot S)^C = I^C \oslash S$
\end{center}
In contrast to Erosion and Dilation, Thinning and thickening will stop at some point. Erosion and Dilation will continue until the whole image is either background or forground only. 

\underline{\textbf{Skeletonization and the Medial Axis Transform (MAT):}} The MAT are stick-figure representations of a region $X \subset \mathbb{R}^2$. Essentially what it is, is starting a grassfire at the boundary of the region. The skeleton is the set of points at which two fire fronts meet
\begin{figure}[H]
\centering
\begin{subfigure}[b]{0.32\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC38.png}
\end{subfigure}
\end{figure}
\underline{\textbf{Medial Axis Transform (MAT):}} Provides an alternative skeleton definition. The skeleton is the union of cneteres of maximal discs within X. A maximal disc is a circular subset of X that touches the boundary in at least two places. The MAT is the skeleton with the maximal disc radius retained at each point.

\begin{figure}[H]
\centering
\begin{subfigure}[b]{0.32\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC39.png}
\end{subfigure}
\end{figure}

\chapter{Convolution and Filtering}


\underline{\textbf{Image Filtering}} The modification of pixels in an image based on some function of a local neighborhood of the pixels
\begin{figure}[H]
\centering
\begin{subfigure}[b]{0.32\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC40.png}
\end{subfigure}
\end{figure}


\underline{\textbf{Linear Shift-invariant Filtering:}} Modification of pixels based on neighborhood using a linear combination of neighbors. Shift invariant means we do the same for each pixel. With these filters we can:
\begin{itemize}
\item Low level image processing operations
\item smoothing and noise reduction
\item sharpen
\item detection and enhancement
\end{itemize}

\underline{\textbf{Linear Filter:}} L is a linear operation if
\begin{center}
$L[\alpha l_1 + \beta l_2] = \alpha L[l_1] + \beta L[l_2]$
\end{center}
The output $l'$ of linear image operation is a weighted sum of each pixel in the input I.
\begin{center}
$I'(x,y) = \displaystyle\sum_{(i,j) \in N(x,y)} K(x,y;i,j)I(i,j)$
\end{center}
Where:
\begin{itemize}
\item I is the input image
\item I' the output,
\item K the kernel of the operation
\item N(m,n) is the neighbourhood of (m,n)
\end{itemize}
If  the operations are \textbf{shift-invariant} then K does not depend on  (x,y) and we use the same weights everywhere

\section{Correlation}

Linear operation of correlation:
\begin{center}
$I' = K \circ I$\\
$I'(x,y) = \displaystyle \sum_{(i,j) \in N(x,y)} K(i,j)I(x+i,y+j)$
\end{center}

\begin{figure}[H]
\centering
\begin{subfigure}[b]{0.32\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC41.png}
\end{subfigure}
\end{figure}

\section{Convolution}

Convolution is a blurring function. Convolution is a linear operation:
\begin{center}
$I' = K \circ I$\\
$I'(x,y) = \displaystyle \sum_{(i,j) \in N(x,y)} K(i,j)I(x-i,y-j)$
\end{center}

The difference between Convolution and correlation is that the kernel is reversed. If your kernel is symmetric the Convolution is equivalent to Correlation.

\begin{figure}[H]
\centering
\begin{subfigure}[b]{0.32\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC42.png}
\end{subfigure}
\end{figure}

For the edge of the image we have no data, hence applying the filter around the edge will shrink the image. Applying many filters to an image would eventually cause the image to disappear. In order to prevent this we must make some assumptions of the what the filter should apply when at the edge of the image. Possible methods are :
\begin{itemize}
\item clip filter
\item wrap around
\item copy edge
\item reflect across edge
\item vary filter near edge
\end{itemize}

\section{Separable Kernels} Have the following attribute:
\begin{center}
$K(m,n) = f(m)g(n)$
\end{center}
Hence the Kernel can be written as the product of 2 vectors.  For a rectangular neighbourhood with size $(2M+1)\ast(2N+1)$
\begin{center}
$I'(m,n) = f \cdot (g \cdot I(N(m,n)))$\\
$I''(m,n) = \displaystyle\sum_{j-=M}^M g(j)\cdot I(m,n-j)$
\end{center}
Separating the Kernels has a computational advantage because vector matrix multiplication is more efficient.
\section{Gaussian Kernel}
The idea is to have the weight contributions of neighboring pixels proportional to their nearness
\begin{figure}[H]
\centering
\begin{subfigure}[b]{0.32\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC43.png}
\end{subfigure}
\end{figure}
The constant factor at the front of $G_{\sigma}$ makes the volume sum to 1

\underline{\textbf{Smoothing with Gaussian vs Box Filter}  }
\begin{figure}[H]
\centering
\begin{subfigure}[b]{0.32\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC44.png}
\end{subfigure}
\begin{subfigure}[b]{0.32\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC45.png}
\end{subfigure}
\end{figure}
Comparing the two filters, the box image still shows artifacts. The reason being that when applying the box filter convolution on the image we spread out the values such that they get fainter, yet it is still a box, hence we still get a strong edge effect. The fact that the filter itself has strong edges is a problem.

The gaussian kernel is separable and becomes the product of 2 one dimensional gaussians. i.e 
\begin{center}
$g(x,y) = g(x)g(y)$
\end{center}
The amount of smoothing depends on $\sigma$ and the kernel size.
The top benefits of the Gaussian smoothing kernel:
\begin{itemize}
\item Rotationally symmetric 
\item Has a single lobe (Neighbors influence decreases monotonically)
\item Still one lobe in frequency domain (no corruption from high frequencies) 
\item Simple relationship to $\sigma$
\item Easy to implement efficiently
\end{itemize}

\underline{\textbf{Scale Space}} A Convolution of a Gaussian with standard deviation $\sigma$ with itself is a Gaussian with standard deviation of $\sigma\sqrt{2}$. The repeated convolution by a Gaussian filter produces the scale space of an image. 
\begin{figure}[H]
\centering
\begin{subfigure}[b]{0.32\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC46.png}
\end{subfigure}
\end{figure}

\underline{\textbf{Differential FIlters:}}
\begin{figure}[H]
\centering
\begin{subfigure}[b]{0.32\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC47.png}
\end{subfigure}
\end{figure}
We can see that both of these filters average out (sum of the elements = 0), hence in homogeneous parts of the image the response of the filter will be zero. If we sth that is brighter on one side than the other then we will have a larger response. (for vertical edges). The Sobel operator has more weight on the central pixel hence its a smoother response.

\underline{\textbf{High-pass filters}}
\begin{figure}[H]
\centering
\begin{subfigure}[b]{0.32\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC48.png}
\end{subfigure}
\end{figure}
For these the highest response is given from isolated pixels surrounded by pixels of high contrast

\underline{\textbf{Filters are templates}} Filter at some point can be seen as taking a dot-product between the image and some vector. Filtering the image corresponds to a set of dot products. Filters look like the effects they are intended to find and will get the largest response to regions which look like the filter

\underline{\textbf{Image Sharpening (Enhancement)}} Increases the high frequency components to enhance edges. Sharpening has the following  structure:
\begin{center}
$I' = I + \alpha |k\cdot I|$
\end{center}
where k is a high-pass filter kernel and $\alpha$ is a scalar in $[0,1]$

\chapter{Image Features}
 
\section{Template Matching:} Locate an onject, described by a template $t(x,y)$ in the image $s(x,y)$
\begin{figure}[H]
\centering
\begin{subfigure}[b]{0.32\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC49.png}
\end{subfigure}
\end{figure}
We search for the best match by minimizing mean-squared error
\begin{center}
$E(p,q) = \displaystyle\sum_{x=-\infty}^{\infty}  \displaystyle\sum_{y=-\infty}^{\infty} [s(x,y) - t(x-p,y-q)]^2$\\
$=\displaystyle\sum_{x=-\infty}^{\infty}  \displaystyle\sum_{y=-\infty}^{\infty}|s(x,y)|^2 + \displaystyle\sum_{x=-\infty}^{\infty}  \displaystyle\sum_{y=-\infty}^{\infty} |t(x,y)|^2 - 2 \displaystyle\sum_{x=-\infty}^{\infty}  \displaystyle\sum_{y=-\infty}^{\infty} s(x,y)t(x-p.y-q)$
\end{center}
In the last equation the terms are constant with the exception of the last one, which has the form of the correlation operator. Hence the problem is equivalent too maximizing area correlation:
\begin{center}
$r(p,q) = \displaystyle\sum_{x=-\infty}^{\infty}  \displaystyle\sum_{y=-\infty}^{\infty} s(x,y)t(x-p,y-q) \ast t(-p,-q)$
\end{center}
Area correlation is equivalent to convolution of image $s(x,y)$ with-impulse response $t(-x,-y)$.
\begin{figure}[H]
\centering
\begin{subfigure}[b]{0.32\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC50.png}
\end{subfigure}
\end{figure} 

\section{Edge detection}

An Edge is a region of strong change in intensity, hence we look for a region with a large gradient. The gradient of an image is the local change of the image. The size of the gradient is given by:
\begin{center}
$|grad(f(x,y))| = \sqrt{\frac{\delta f}{\delta x}^2 + \frac{\delta f}{\delta y}^2}$
\end{center}
Since we are only interested in finding the edge we do not need to worry about the direction. The following image shows examples of edge detection filters.
 \begin{figure}[H]
\centering
\begin{subfigure}[b]{0.32\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC51.png}
\end{subfigure}
\end{figure} 
The left matrix is the derivative of x and the right is the derivative of y.
An edge has a sign. Either it can go from bright to dark or dark to bright which have the inverse gradient orientation.

\underline{\textbf{Laplacian operator}} Another method to detect discontiuities i.e edges. We now consider the second derivative.
\begin{center}
$\nabla^2f(x,y) = \frac{\delta^2f(x,y)}{\delta x^2} + \frac{\delta^2 f(x,y)}{\delta y^2}$
\end{center}
The laplacian operator has the following properties:
\begin{itemize}
\item Isotropic (rotationally invariant)
\item Zero-crossings mark edge location
\end{itemize}
We can make a discrete space approximation by convoluting with the 3x3 impulse response:
 \begin{figure}[H]
\centering
\begin{subfigure}[b]{0.32\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC52.png}
\end{subfigure}
\begin{subfigure}[b]{0.32\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC53.png}
\end{subfigure}
\end{figure} 
The challenge with detecting zero crossing is that images have alot of noise and hence there could be many small oscillations causing zero crossings which we are not interested in. We can reduce some of the noise by blurring the image first (e.g with a gaussian filter).  The Laplacian operator responds equally to strong and weak edges, hence we can also solve this problem by looking at the gradient magnitude (i.e the first derivative), if the magnitude is above a certain value we then mark the zero crossing as an edge.\\

Blurring of an image with Gaussian and Laplacian operator can be combined into a convolution with Laplacian of Gaussian \textbf{(LoG)} operator which has the following form:
\begin{center}
$LoG(x,y) = -\frac{1}{\pi \sigma^4}\big[ 1- \frac{x^2 + y^2}{2\sigma^2}\big]e^{-\frac{x^2+y^2}{2\sigma^2}}$ 
\end{center}

\section{Canny edge detector}
Works in 5 steps:
\begin{enumerate}
\item Smooth image with a Gaussian filter
\item Compute gradient magnitude and direction of gradient
 \begin{figure}[H]
\centering
\begin{subfigure}[b]{0.32\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC54.png}
\end{subfigure}
\end{figure} 
\item Apply nonmaxima supression to gradient magnitude image
\item Double thresholding to detect strong and weak edge pixels
\item Reject weak edge pixels not connected with strong edge pixels 
\end{enumerate}

We Quantize the edge normal (direction of the edge) to one of four directions
\begin{itemize}
\item horizontal
\item -45$^\circ$
\item vertical
\item +45$^\circ$
\end{itemize}
For nonmaxima suppression we find the direction of the largest gradient and if  $M(x,y)$ is smaller than either of its neighbors in the edge normal direction then we suppress it otherwise we keep it.
 \begin{figure}[H]
\centering
\begin{subfigure}[b]{0.32\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC55.png}
\end{subfigure}
\end{figure} 
Canny thresholding has the following form:
 \begin{figure}[H]
\centering
\begin{subfigure}[b]{0.32\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC56.png}
\end{subfigure}
\end{figure} 
We discard all the weak edges which arent connected to strong edges.

\section{Hough transform}

Our goal is to fit a straight line or curve to a set of edge pixels. Lines are defined by the following equation:
\begin{center}
$y = mx + c$
\end{center}
Given a pixel p=(x,y) we can find all parameters m and c such that the line goes through the pixel, we see that these two spaces are symmetric i.e (-c = mx - y) hence the same way a choice of m and c define a line in the x,y space, a choice of x and y will define a line in the parameter space
 \begin{figure}[H]
\centering
\begin{subfigure}[b]{0.32\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC57.png}
\end{subfigure}
\end{figure} 
We now subdivide the (m,c) plane into discrete "bins", and initialize their count to 0. For each edge pixel x,y we draw a line in the parameter space and increment the bin counts along the line. Our goal is to find a line in the (x,y) space, which contains as many lines as possible in the (m,c) space, hence we need to find the bin in the (m,c) space which has the highest count (peak)
 \begin{figure}[H]
\centering
\begin{subfigure}[b]{0.32\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC58.png}
\end{subfigure}
\end{figure} 
The downside to this choice of parameter space is, that if you have a vertical line then it cannot be expressed with this parameter space. Hence we use an alternative parameterization which avoids this infinite slope problem.  
 \begin{figure}[H]
\centering
\begin{subfigure}[b]{0.32\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC59.png}
\end{subfigure}
\end{figure} 
\underline{example:}
Given an image, we first run edge detection on it, then draw up the edges in the Hough space (seen on the right)
 \begin{figure}[H]
\centering
\begin{subfigure}[b]{0.32\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC60.png}
\end{subfigure}
\end{figure} 
The peaks in the Hough space in the image above are the two sets of orthogonal lines. The length of the line (in pixels) is approximately the number of counts the peak has.
\underline{\textbf{Circle detection by Hough transform}}
 \begin{figure}[H]
\centering
\begin{subfigure}[b]{0.32\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC61.png}
\end{subfigure}
\begin{subfigure}[b]{0.32\linewidth}
\includegraphics[width = \linewidth,scale = 1]{VC62.png}
\end{subfigure}
\end{figure} 

\underline{\textbf{Detecting corner points}} When trying to localize a point on an edge it can be difficult because points along the edge could be quite similiar, whereas a corner pixel is different from all its neighbours. Desirable proporties of corner detector are:
\begin{itemize}
\item Accurate localization
\item invariance against shift, rotation,scale, brightness change
\item Robust against noise, high repeatability
\end{itemize}
To find corn








\chapter{Fourier Transform}




































 \end{document}